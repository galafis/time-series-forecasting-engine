{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Tutorial 1: Introdu√ß√£o ao Time Series Forecasting Engine\n",
    "\n",
    "Este notebook fornece uma introdu√ß√£o pr√°tica ao uso do Time Series Forecasting Engine, cobrindo:\n",
    "1. Carregamento e visualiza√ß√£o de dados\n",
    "2. Pr√©-processamento b√°sico\n",
    "3. Treinamento de modelos simples\n",
    "4. Avalia√ß√£o e visualiza√ß√£o de resultados\n",
    "\n",
    "## Instala√ß√£o\n",
    "\n",
    "Certifique-se de ter o pacote instalado:\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úì Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gerando Dados de Exemplo\n",
    "\n",
    "Vamos criar uma s√©rie temporal sint√©tica com:\n",
    "- Tend√™ncia linear\n",
    "- Sazonalidade anual e semanal\n",
    "- Ru√≠do aleat√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(n_points=365*2, start_date='2020-01-01'):\n",
    "    \"\"\"\n",
    "    Gera dados de s√©rie temporal sint√©tica.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - n_points: n√∫mero de pontos (dias)\n",
    "    - start_date: data inicial\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start=start_date, periods=n_points, freq='D')\n",
    "    \n",
    "    # Componentes\n",
    "    trend = np.linspace(100, 200, n_points)  # Tend√™ncia crescente\n",
    "    seasonal_yearly = 20 * np.sin(2 * np.pi * np.arange(n_points) / 365)  # Sazonalidade anual\n",
    "    seasonal_weekly = 10 * np.sin(2 * np.pi * np.arange(n_points) / 7)   # Sazonalidade semanal\n",
    "    noise = np.random.normal(0, 5, n_points)  # Ru√≠do\n",
    "    \n",
    "    # Combina√ß√£o\n",
    "    values = trend + seasonal_yearly + seasonal_weekly + noise\n",
    "    \n",
    "    return pd.Series(values, index=dates, name='vendas')\n",
    "\n",
    "# Gerar dados\n",
    "data = generate_sample_data()\n",
    "\n",
    "print(f\"Dados gerados: {len(data)} observa√ß√µes\")\n",
    "print(f\"Per√≠odo: {data.index[0]} a {data.index[-1]}\")\n",
    "print(f\"\\nPrimeiras 5 observa√ß√µes:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualiza√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o visualizador\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from src.visualization import TimeSeriesVisualizer\n",
    "\n",
    "visualizer = TimeSeriesVisualizer()\n",
    "\n",
    "# Plotar s√©rie temporal\n",
    "fig = visualizer.plot_time_series(\n",
    "    data,\n",
    "    title=\"S√©rie Temporal de Vendas\",\n",
    "    show_trend=True\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEstat√≠sticas descritivas:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Divis√£o Treino/Teste\n",
    "\n",
    "Para s√©ries temporais, sempre dividimos os dados respeitando a ordem temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divis√£o 80/20\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "test = data[train_size:]\n",
    "\n",
    "print(f\"Conjunto de treino: {len(train)} observa√ß√µes ({train.index[0]} a {train.index[-1]})\")\n",
    "print(f\"Conjunto de teste: {len(test)} observa√ß√µes ({test.index[0]} a {test.index[-1]})\")\n",
    "\n",
    "# Visualizar divis√£o\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train.index, train.values, label='Treino', color='blue', alpha=0.7)\n",
    "plt.plot(test.index, test.values, label='Teste', color='green', alpha=0.7)\n",
    "plt.axvline(x=train.index[-1], color='red', linestyle='--', label='Divis√£o')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Vendas')\n",
    "plt.title('Divis√£o Treino/Teste')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pr√©-processamento B√°sico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import TimeSeriesPreprocessor\n",
    "\n",
    "preprocessor = TimeSeriesPreprocessor()\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"Valores faltantes: {train.isna().sum()}\")\n",
    "\n",
    "# Detectar outliers\n",
    "outliers_mask = preprocessor.detect_outliers(train, method='iqr', threshold=3.0)\n",
    "print(f\"Outliers detectados: {outliers_mask.sum()}\")\n",
    "\n",
    "# Remover outliers\n",
    "train_clean = preprocessor.remove_outliers(train, method='iqr', threshold=3.0)\n",
    "print(f\"Dados ap√≥s remo√ß√£o de outliers: {len(train_clean)} observa√ß√µes\")\n",
    "\n",
    "# Testar estacionariedade\n",
    "is_stationary, test_result = preprocessor.test_stationarity(train_clean)\n",
    "print(f\"\\nTeste de Estacionariedade (ADF):\")\n",
    "print(f\"  Estacion√°rio: {is_stationary}\")\n",
    "print(f\"  Estat√≠stica ADF: {test_result['adf_statistic']:.4f}\")\n",
    "print(f\"  p-valor: {test_result['p_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo ARIMA\n",
    "\n",
    "Vamos treinar um modelo ARIMA com sele√ß√£o autom√°tica de par√¢metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ARIMAForecaster\n",
    "\n",
    "# Criar e treinar modelo\n",
    "arima = ARIMAForecaster(auto_select=True)\n",
    "print(\"Treinando modelo ARIMA...\")\n",
    "arima.fit(train_clean)\n",
    "print(\"‚úì Modelo treinado!\")\n",
    "\n",
    "# Fazer previs√µes\n",
    "predictions = arima.predict(steps=len(test))\n",
    "print(f\"\\nPrevis√µes geradas: {len(predictions)} pontos\")\n",
    "\n",
    "# Obter intervalos de confian√ßa\n",
    "pred_with_intervals = arima.predict_with_intervals(steps=len(test), confidence=0.95)\n",
    "predictions, lower_bound, upper_bound = pred_with_intervals\n",
    "print(\"‚úì Intervalos de confian√ßa calculados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import ModelEvaluator\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Calcular m√©tricas\n",
    "metrics = evaluator.calculate_metrics(test.values, predictions.values)\n",
    "\n",
    "print(\"M√©tricas de Erro:\")\n",
    "print(f\"  MAE (Erro Absoluto M√©dio):          {metrics['MAE']:.2f}\")\n",
    "print(f\"  RMSE (Raiz do Erro Quadr√°tico):     {metrics['RMSE']:.2f}\")\n",
    "print(f\"  MAPE (Erro Percentual Absoluto):    {metrics['MAPE']:.2f}%\")\n",
    "print(f\"  sMAPE (MAPE Sim√©trico):             {metrics['sMAPE']:.2f}%\")\n",
    "print(f\"  R¬≤ (Coeficiente de Determina√ß√£o):   {metrics['R2']:.4f}\")\n",
    "print(f\"  MASE (Erro Absoluto Escalado):      {metrics['MASE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualiza√ß√£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da previs√£o\n",
    "fig = visualizer.plot_forecast(\n",
    "    train_clean,\n",
    "    test,\n",
    "    predictions,\n",
    "    lower_bound,\n",
    "    upper_bound,\n",
    "    title=\"ARIMA: Previs√£o vs Real\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de res√≠duos\n",
    "if hasattr(arima, 'residuals_') and arima.residuals_ is not None:\n",
    "    fig = visualizer.plot_residuals(arima.residuals_)\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas dos res√≠duos\n",
    "    residual_stats = evaluator.residual_analysis(arima, test, predictions)\n",
    "    print(\"\\nAn√°lise de Res√≠duos:\")\n",
    "    print(f\"  M√©dia: {residual_stats['mean']:.4f}\")\n",
    "    print(f\"  Desvio padr√£o: {residual_stats['std']:.4f}\")\n",
    "    print(f\"  Normalmente distribu√≠do: {residual_stats['is_normal']}\")\n",
    "    print(f\"  Ru√≠do branco (sem autocorrela√ß√£o): {residual_stats['is_white_noise']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modelo Prophet\n",
    "\n",
    "Agora vamos testar o Prophet, que √© especialmente bom para capturar m√∫ltiplas sazonalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ProphetForecaster\n",
    "\n",
    "# Criar e treinar modelo\n",
    "prophet = ProphetForecaster(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "print(\"Treinando modelo Prophet...\")\n",
    "prophet.fit(train_clean)\n",
    "print(\"‚úì Modelo treinado!\")\n",
    "\n",
    "# Fazer previs√µes\n",
    "prophet_predictions = prophet.predict(steps=len(test))\n",
    "prophet_pred_intervals = prophet.predict_with_intervals(steps=len(test), confidence=0.95)\n",
    "prophet_predictions, prophet_lower, prophet_upper = prophet_pred_intervals\n",
    "\n",
    "# Avaliar\n",
    "prophet_metrics = evaluator.calculate_metrics(test.values, prophet_predictions.values)\n",
    "\n",
    "print(\"\\nM√©tricas Prophet:\")\n",
    "print(f\"  MAE:   {prophet_metrics['MAE']:.2f}\")\n",
    "print(f\"  RMSE:  {prophet_metrics['RMSE']:.2f}\")\n",
    "print(f\"  MAPE:  {prophet_metrics['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar Prophet\n",
    "fig = visualizer.plot_forecast(\n",
    "    train_clean,\n",
    "    test,\n",
    "    prophet_predictions,\n",
    "    prophet_lower,\n",
    "    prophet_upper,\n",
    "    title=\"Prophet: Previs√£o vs Real\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compara√ß√£o de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar modelos\n",
    "models = [arima, prophet]\n",
    "comparison = evaluator.compare_models(models, train_clean, test)\n",
    "\n",
    "print(\"\\nCompara√ß√£o de Modelos:\")\n",
    "print(comparison)\n",
    "\n",
    "# Visualizar compara√ß√£o\n",
    "fig = visualizer.plot_model_comparison(comparison, metric='RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cross-Validation\n",
    "\n",
    "Valida√ß√£o cruzada para s√©ries temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novo modelo para CV\n",
    "cv_model = ARIMAForecaster(auto_select=True)\n",
    "\n",
    "# Realizar cross-validation\n",
    "print(\"Executando cross-validation (pode demorar alguns minutos)...\")\n",
    "cv_results = evaluator.time_series_cv(\n",
    "    model=cv_model,\n",
    "    data=data,\n",
    "    n_splits=5,\n",
    "    test_size=30\n",
    ")\n",
    "\n",
    "print(\"\\nResultados de Cross-Validation:\")\n",
    "print(f\"  RMSE: {cv_results['RMSE_mean']:.2f} ¬± {cv_results['RMSE_std']:.2f}\")\n",
    "print(f\"  MAE:  {cv_results['MAE_mean']:.2f} ¬± {cv_results['MAE_std']:.2f}\")\n",
    "print(f\"  MAPE: {cv_results['MAPE_mean']:.2f}% ¬± {cv_results['MAPE_std']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "Neste tutorial, voc√™ aprendeu:\n",
    "\n",
    "1. ‚úÖ Como gerar e visualizar dados de s√©ries temporais\n",
    "2. ‚úÖ Como realizar pr√©-processamento b√°sico\n",
    "3. ‚úÖ Como treinar modelos ARIMA e Prophet\n",
    "4. ‚úÖ Como avaliar modelos usando m√∫ltiplas m√©tricas\n",
    "5. ‚úÖ Como comparar diferentes modelos\n",
    "6. ‚úÖ Como usar cross-validation para s√©ries temporais\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- **Tutorial 2:** Deep Learning com LSTM\n",
    "- **Tutorial 3:** Modelos Ensemble\n",
    "- **Tutorial 4:** Pr√©-processamento Avan√ßado\n",
    "- **Tutorial 5:** Casos de Uso Reais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
