{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Tutorial 2: Pr√©-processamento Avan√ßado e Feature Engineering\n",
    "\n",
    "Este notebook cobre t√©cnicas avan√ßadas de pr√©-processamento:\n",
    "1. Decomposi√ß√£o sazonal\n",
    "2. Transforma√ß√µes de dados\n",
    "3. Feature engineering\n",
    "4. Tratamento de outliers\n",
    "5. Estacionariedade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from src.preprocessing import TimeSeriesPreprocessor\n",
    "from src.visualization import TimeSeriesVisualizer\n",
    "\n",
    "preprocessor = TimeSeriesPreprocessor()\n",
    "visualizer = TimeSeriesVisualizer()\n",
    "\n",
    "print(\"‚úì Bibliotecas carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gera√ß√£o de Dados Complexos\n",
    "\n",
    "Vamos criar dados com m√∫ltiplas sazonalidades e outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complex_data(n_points=365*3):\n",
    "    \"\"\"Gera s√©rie temporal complexa com m√∫ltiplas sazonalidades e outliers.\"\"\"\n",
    "    dates = pd.date_range('2020-01-01', periods=n_points, freq='D')\n",
    "    \n",
    "    # Tend√™ncia n√£o-linear (exponencial)\n",
    "    t = np.arange(n_points)\n",
    "    trend = 100 * np.exp(t / (n_points * 2))\n",
    "    \n",
    "    # Sazonalidade anual\n",
    "    seasonal_yearly = 30 * np.sin(2 * np.pi * t / 365)\n",
    "    \n",
    "    # Sazonalidade mensal\n",
    "    seasonal_monthly = 15 * np.sin(2 * np.pi * t / 30)\n",
    "    \n",
    "    # Sazonalidade semanal\n",
    "    seasonal_weekly = 10 * np.sin(2 * np.pi * t / 7)\n",
    "    \n",
    "    # Ru√≠do\n",
    "    noise = np.random.normal(0, 5, n_points)\n",
    "    \n",
    "    # Combinar\n",
    "    values = trend + seasonal_yearly + seasonal_monthly + seasonal_weekly + noise\n",
    "    \n",
    "    # Adicionar outliers (eventos especiais)\n",
    "    outlier_indices = np.random.choice(n_points, size=10, replace=False)\n",
    "    values[outlier_indices] += np.random.normal(50, 20, 10)\n",
    "    \n",
    "    # Adicionar valores faltantes\n",
    "    missing_indices = np.random.choice(n_points, size=15, replace=False)\n",
    "    values[missing_indices] = np.nan\n",
    "    \n",
    "    return pd.Series(values, index=dates, name='vendas')\n",
    "\n",
    "data = generate_complex_data()\n",
    "\n",
    "print(f\"Dados gerados: {len(data)} pontos\")\n",
    "print(f\"Valores faltantes: {data.isna().sum()}\")\n",
    "print(f\"Per√≠odo: {data.index[0]} a {data.index[-1]}\")\n",
    "\n",
    "# Visualizar\n",
    "visualizer.plot_time_series(data, title=\"S√©rie Temporal Complexa (com outliers e NaN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tratamento de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar m√©todos de imputa√ß√£o\n",
    "methods = ['interpolate', 'ffill', 'bfill', 'mean']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    filled = preprocessor.handle_missing_values(data.copy(), method=method)\n",
    "    \n",
    "    axes[idx].plot(data.index, data.values, 'o', alpha=0.3, label='Original (com NaN)', markersize=2)\n",
    "    axes[idx].plot(filled.index, filled.values, '-', label=f'Preenchido ({method})', linewidth=1)\n",
    "    axes[idx].set_title(f'M√©todo: {method}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Usar melhor m√©todo (interpola√ß√£o)\n",
    "data_filled = preprocessor.handle_missing_values(data, method='interpolate')\n",
    "print(f\"‚úì Valores faltantes preenchidos: {data_filled.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detec√ß√£o e Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar m√©todos de detec√ß√£o\n",
    "methods = ['iqr', 'zscore', 'modified_zscore']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    outliers_mask = preprocessor.detect_outliers(data_filled, method=method)\n",
    "    \n",
    "    axes[idx].plot(data_filled.index, data_filled.values, '-', label='Dados', linewidth=1)\n",
    "    axes[idx].scatter(\n",
    "        data_filled.index[outliers_mask],\n",
    "        data_filled.values[outliers_mask],\n",
    "        color='red',\n",
    "        s=50,\n",
    "        label=f'Outliers ({outliers_mask.sum()})',\n",
    "        zorder=5\n",
    "    )\n",
    "    axes[idx].set_title(f'M√©todo: {method}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Remover outliers com IQR\n",
    "data_clean = preprocessor.remove_outliers(data_filled, method='iqr', threshold=3.0)\n",
    "print(f\"‚úì Outliers removidos\")\n",
    "print(f\"  Dados originais: {len(data_filled)}\")\n",
    "print(f\"  Dados limpos: {data_clean.notna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decomposi√ß√£o Sazonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposi√ß√£o aditiva\n",
    "decomposition = preprocessor.decompose(data_clean, model='additive', period=365)\n",
    "\n",
    "# Visualizar componentes\n",
    "fig = visualizer.plot_decomposition(\n",
    "    trend=decomposition.trend,\n",
    "    seasonal=decomposition.seasonal,\n",
    "    residual=decomposition.residual\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Componentes extra√≠dos:\")\n",
    "print(f\"  Tend√™ncia: {decomposition.trend.notna().sum()} pontos\")\n",
    "print(f\"  Sazonal: {decomposition.seasonal.notna().sum()} pontos\")\n",
    "print(f\"  Residual: {decomposition.residual.notna().sum()} pontos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transforma√ß√µes de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar transforma√ß√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].plot(data_clean.index, data_clean.values, linewidth=1)\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log\n",
    "data_log = preprocessor.transform(data_clean, method='log')\n",
    "axes[0, 1].plot(data_log.index, data_log.values, linewidth=1, color='orange')\n",
    "axes[0, 1].set_title('Transforma√ß√£o Logar√≠tmica')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Box-Cox\n",
    "data_boxcox = preprocessor.transform(data_clean, method='boxcox')\n",
    "axes[1, 0].plot(data_boxcox.index, data_boxcox.values, linewidth=1, color='green')\n",
    "axes[1, 0].set_title('Transforma√ß√£o Box-Cox')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Diferencia√ß√£o\n",
    "data_diff = preprocessor.difference(data_clean, periods=1)\n",
    "axes[1, 1].plot(data_diff.index, data_diff.values, linewidth=1, color='red')\n",
    "axes[1, 1].set_title('Diferencia√ß√£o (1¬™ ordem)')\n",
    "axes[1, 1].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Teste de Estacionariedade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar dados originais\n",
    "is_stationary, result = preprocessor.test_stationarity(data_clean)\n",
    "\n",
    "print(\"Teste ADF (Augmented Dickey-Fuller):\")\n",
    "print(f\"  Dados originais:\")\n",
    "print(f\"    Estacion√°rio: {is_stationary}\")\n",
    "print(f\"    Estat√≠stica: {result['adf_statistic']:.4f}\")\n",
    "print(f\"    p-valor: {result['p_value']:.4f}\")\n",
    "print(f\"    Valores cr√≠ticos:\")\n",
    "for key, value in result['critical_values'].items():\n",
    "    print(f\"      {key}: {value:.4f}\")\n",
    "\n",
    "# Se n√£o for estacion√°rio, tornar estacion√°rio\n",
    "if not is_stationary:\n",
    "    print(\"\\n‚Üí Tornando s√©rie estacion√°ria...\")\n",
    "    data_stationary = preprocessor.make_stationary(data_clean)\n",
    "    \n",
    "    is_stat_after, result_after = preprocessor.test_stationarity(data_stationary)\n",
    "    print(f\"\\n  Ap√≥s transforma√ß√£o:\")\n",
    "    print(f\"    Estacion√°rio: {is_stat_after}\")\n",
    "    print(f\"    p-valor: {result_after['p_value']:.4f}\")\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    axes[0].plot(data_clean.index, data_clean.values, linewidth=1)\n",
    "    axes[0].set_title('S√©rie Original (N√£o-Estacion√°ria)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(data_stationary.index, data_stationary.values, linewidth=1, color='green')\n",
    "    axes[1].set_title('S√©rie Estacion√°ria')\n",
    "    axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de lag\n",
    "features_lag = preprocessor.create_lag_features(\n",
    "    data_clean,\n",
    "    lags=[1, 7, 14, 30]\n",
    ")\n",
    "\n",
    "print(\"Features de Lag criadas:\")\n",
    "print(features_lag.head(40))\n",
    "print(f\"\\nDimens√µes: {features_lag.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de rolling statistics\n",
    "features_rolling = preprocessor.create_rolling_features(\n",
    "    data_clean,\n",
    "    windows=[7, 14, 30],\n",
    "    statistics=['mean', 'std', 'min', 'max']\n",
    ")\n",
    "\n",
    "print(\"Features Rolling criadas:\")\n",
    "print(features_rolling.columns.tolist())\n",
    "print(f\"\\nDimens√µes: {features_rolling.shape}\")\n",
    "\n",
    "# Visualizar algumas features\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(features_rolling.index, features_rolling['value'], label='Original', linewidth=1)\n",
    "axes[0].plot(features_rolling.index, features_rolling['rolling_mean_7'], label='M√©dia M√≥vel 7d', linewidth=2)\n",
    "axes[0].plot(features_rolling.index, features_rolling['rolling_mean_30'], label='M√©dia M√≥vel 30d', linewidth=2)\n",
    "axes[0].set_title('M√©dias M√≥veis')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(features_rolling.index, features_rolling['rolling_std_7'], label='Desvio Padr√£o 7d', linewidth=2)\n",
    "axes[1].plot(features_rolling.index, features_rolling['rolling_std_30'], label='Desvio Padr√£o 30d', linewidth=2)\n",
    "axes[1].set_title('Volatilidade (Desvio Padr√£o M√≥vel)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features temporais\n",
    "features_time = preprocessor.create_time_features(data_clean)\n",
    "\n",
    "print(\"Features Temporais criadas:\")\n",
    "print(features_time.head(10))\n",
    "print(f\"\\nColunas: {features_time.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar conjunto completo de features\n",
    "features_complete = preprocessor.create_features(\n",
    "    data_clean,\n",
    "    lags=[1, 7, 14, 30],\n",
    "    rolling_windows=[7, 14, 30],\n",
    "    time_features=True,\n",
    "    seasonal_features=True\n",
    ")\n",
    "\n",
    "print(f\"Features completas criadas: {features_complete.shape[1]} features\")\n",
    "print(f\"\\nLista de features:\")\n",
    "for col in features_complete.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lise de Correla√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular correla√ß√µes\n",
    "features_subset = features_complete[[\n",
    "    'value', 'lag_1', 'lag_7', 'lag_30',\n",
    "    'rolling_mean_7', 'rolling_std_7',\n",
    "    'day_of_week', 'month'\n",
    "]].dropna()\n",
    "\n",
    "correlation_matrix = features_subset.corr()\n",
    "\n",
    "# Visualizar heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1\n",
    ")\n",
    "plt.title('Matriz de Correla√ß√£o das Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features mais correlacionadas com target\n",
    "target_corr = correlation_matrix['value'].drop('value').sort_values(ascending=False)\n",
    "print(\"\\nFeatures mais correlacionadas com target:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar m√©todos de escalonamento\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].hist(data_clean.values, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].set_xlabel('Valor')\n",
    "axes[0, 0].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# Min-Max\n",
    "data_minmax = preprocessor.scale(data_clean, method='minmax')\n",
    "axes[0, 1].hist(data_minmax.values, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_title('Min-Max Scaling [0, 1]')\n",
    "axes[0, 1].set_xlabel('Valor')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# Standard\n",
    "data_standard = preprocessor.scale(data_clean, method='standard')\n",
    "axes[1, 0].hist(data_standard.values, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Standard Scaling (Œº=0, œÉ=1)')\n",
    "axes[1, 0].set_xlabel('Valor')\n",
    "axes[1, 0].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# Compara√ß√£o temporal\n",
    "axes[1, 1].plot(data_clean.index, data_clean.values, label='Original', alpha=0.5)\n",
    "axes[1, 1].plot(data_minmax.index, data_minmax.values * 100, label='Min-Max (√ó100)', alpha=0.7)\n",
    "axes[1, 1].plot(data_standard.index, data_standard.values * 10 + 100, label='Standard (√ó10+100)', alpha=0.7)\n",
    "axes[1, 1].set_title('Compara√ß√£o Visual')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Estat√≠sticas dos dados escalonados:\")\n",
    "print(f\"\\nMin-Max:\")\n",
    "print(f\"  M√≠n: {data_minmax.min():.4f}, M√°x: {data_minmax.max():.4f}\")\n",
    "print(f\"\\nStandard:\")\n",
    "print(f\"  M√©dia: {data_standard.mean():.4f}, Desvio: {data_standard.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Pipeline Completo de Pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline end-to-end\n",
    "print(\"Executando pipeline completo de pr√©-processamento...\\n\")\n",
    "\n",
    "# 1. Dados originais\n",
    "print(f\"1. Dados originais: {len(data)} pontos\")\n",
    "print(f\"   Valores faltantes: {data.isna().sum()}\")\n",
    "\n",
    "# 2. Preencher valores faltantes\n",
    "data_step1 = preprocessor.handle_missing_values(data, method='interpolate')\n",
    "print(f\"\\n2. Ap√≥s imputa√ß√£o: {data_step1.isna().sum()} valores faltantes\")\n",
    "\n",
    "# 3. Remover outliers\n",
    "outliers_before = preprocessor.detect_outliers(data_step1, method='iqr').sum()\n",
    "data_step2 = preprocessor.remove_outliers(data_step1, method='iqr', threshold=3.0)\n",
    "print(f\"\\n3. Remo√ß√£o de outliers: {outliers_before} outliers detectados\")\n",
    "\n",
    "# 4. Transforma√ß√£o\n",
    "data_step3 = preprocessor.transform(data_step2, method='log')\n",
    "print(f\"\\n4. Transforma√ß√£o logar√≠tmica aplicada\")\n",
    "\n",
    "# 5. Diferencia√ß√£o\n",
    "data_step4 = preprocessor.difference(data_step3, periods=1)\n",
    "print(f\"\\n5. Diferencia√ß√£o aplicada\")\n",
    "\n",
    "# 6. Escalonamento\n",
    "data_final = preprocessor.scale(data_step4, method='standard')\n",
    "print(f\"\\n6. Escalonamento padr√£o aplicado\")\n",
    "\n",
    "print(f\"\\n‚úì Pipeline conclu√≠do!\")\n",
    "print(f\"  Dados finais: {data_final.notna().sum()} pontos\")\n",
    "print(f\"  M√©dia: {data_final.mean():.4f}\")\n",
    "print(f\"  Desvio: {data_final.std():.4f}\")\n",
    "\n",
    "# Visualizar antes e depois\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(data.index, data.values, linewidth=1)\n",
    "axes[0].set_title('Dados Originais', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(data_final.index, data_final.values, linewidth=1, color='green')\n",
    "axes[1].set_title('Dados Ap√≥s Pipeline Completo', fontsize=14, fontweight='bold')\n",
    "axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "Neste tutorial avan√ßado, voc√™ aprendeu:\n",
    "\n",
    "1. ‚úÖ M√©todos de imputa√ß√£o de valores faltantes\n",
    "2. ‚úÖ Detec√ß√£o e tratamento de outliers\n",
    "3. ‚úÖ Decomposi√ß√£o sazonal\n",
    "4. ‚úÖ Transforma√ß√µes para estabilizar vari√¢ncia\n",
    "5. ‚úÖ Testes de estacionariedade\n",
    "6. ‚úÖ Feature engineering (lags, rolling stats, features temporais)\n",
    "7. ‚úÖ An√°lise de correla√ß√£o\n",
    "8. ‚úÖ Escalonamento de dados\n",
    "9. ‚úÖ Pipeline completo de pr√©-processamento\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- **Tutorial 3:** Deep Learning com LSTM e GRU\n",
    "- **Tutorial 4:** Modelos Ensemble Avan√ßados\n",
    "- **Tutorial 5:** Otimiza√ß√£o de Hiperpar√¢metros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
